{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aa75f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bz2\n",
    "import json\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79dd425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from empath import Empath\n",
    "lexicon = Empath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2dbff01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"mass_shooting\", \"gun_violence\", \"mass_shootings\", \"gun_crime\", \"gun_ownership\", \"gun_crimes\", \"firearms\", \"firearm\", \"CCW_holders\", \"legal_gun_owners\", \"concealed_carriers\", \"violent_crime\", \"gun_owner\", \"accidental_shootings\", \"fire_arms\", \"gun_owners\", \"gun_death\", \"shootings\", \"gun_use\", \"police_shootings\", \"gun_control_laws\", \"home_invasions\", \"gun_deaths\", \"fire_arm\", \"US_police\", \"strict_gun_control\", \"active_shooters\", \"concealed_carry\", \"firearm_owners\", \"homicide\", \"home_invasion\", \"firearm_ownership\", \"mass_shooter\", \"violent_crimes\", \"accidental_shooting\", \"gun_ban\", \"handguns\", \"most_gun_owners\", \"school_shooting\", \"armed_criminals\", \"legal_guns\", \"responsible_gun_owner\", \"school_shootings\", \"assault_weapons\", \"illegal_guns\", \"mass_shooters\", \"law_enforcement_officers\", \"conceal_carry\", \"gun_possession\", \"legal_gun_ownership\", \"homicides\", \"related_crime\", \"strict_gun_laws\", \"CCW\", \"fully_automatic_weapons\", \"related_homicides\", \"gun_culture\", \"responsible_gun_ownership\", \"concealed_carrier\", \"gun_accidents\", \"armed_citizens\", \"gun_laws\", \"gun_control\", \"responsible_gun_owners\", \"related_violence\", \"stricter_gun_laws\", \"concealed_weapons\", \"US_cops\", \"illegal_firearms\", \"illegal_firearm\", \"legal_gun\", \"police_killings\", \"self_defense\", \"hand_guns\", \"armed_citizen\", \"concealed_carry_permits\", \"police_officers\", \"private_gun_ownership\", \"gun_homicides\", \"legal_firearms\", \"Gun_ownership\", \"accidental_deaths\", \"concealed_gun\", \"gun_advocates\", \"gun_law\", \"negligent_discharges\", \"unarmed_black_men\", \"negligent_discharge\", \"unarmed_citizens\", \"unarmed_people\", \"handgun\", \"illegal_gun\", \"American_police\", \"accidental_discharge\", \"law_enforcement\", \"average_gun_owner\"]\n"
     ]
    }
   ],
   "source": [
    "# Generate a lexicon of keywords that relate to gun violence\n",
    "lexicon.create_category(\"gun_violence\", [\"gun_violence\",\"mass_shooting\", \"firearm\",\n",
    "                                         \"firearm_shooting\"],\n",
    "                        model=\"reddit\")\n",
    "# We found that the empath libary is not effective for detecting quotes that pertain to \n",
    "# gun violence using this library, we therefore chose to save the keywords generated by \n",
    "# this function and manually query each line of our dataset. \n",
    "\n",
    "# We noticed this by attempting the .analyse function on a few quotes that were obviously \n",
    "# related to gun violence, but were not detected by the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35280815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store relevant keywords in list\n",
    "# Note that we haven't chosen every keyword from the original category as we feel that\n",
    "# some of them would detect too many irrelevant quotes and would add too much noise to \n",
    "# our dataset. \n",
    "keywords = [\"mass shooting\", \"gun violence\", \"gun crime\", \"gun owner\", \"firearm\", \"gun possession\",\n",
    "            \"accidental shooting\", \"gun death\", \"gun law\", \"gun control\", \"firearm ownership\", \n",
    "            \"mass shooter\", \"school shooting\", \"gun death\", \"firearm owners\", \"gun ban\", \"handguns\", \n",
    "            \"most gun owners\", \"assault weapon\", \"legal gun\", \"fully automatic weapon\", \"gun culture\",\n",
    "            \"gun ownership\", \"gun accidents\", \"armed citizen\", \"concealed carry\", \"concealed carrier\",\n",
    "            \"legal firearm\", \"legal gun\", \"gun homicide\", \"gun advocate\", \"negligent discharge\", \n",
    "            \"accidental discharge\", \"firearm violence\", \"firearm-related violence\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfedc26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword(row):\n",
    "    '''\n",
    "    Filter the quotation of a particular row of a dataframe with a set of keywords.\n",
    "    :param row: dataframe object\n",
    "    :return: list of comma separated matching keywords\n",
    "    '''\n",
    "    keywords = [\"mass shooting\", \"gun violence\", \"gun crime\", \"gun owner\", \"firearm\", \"gun possession\",\n",
    "            \"accidental shooting\", \"gun death\", \"gun law\", \"gun control\", \"firearm ownership\", \n",
    "            \"mass shooter\", \"school shooting\", \"gun death\", \"firearm owners\", \"gun ban\", \"handguns\", \n",
    "            \"most gun owners\", \"assault weapon\", \"legal gun\", \"fully automatic weapon\", \"gun culture\",\n",
    "            \"gun ownership\", \"gun accidents\", \"armed citizen\", \"concealed carry\", \"concealed carrier\",\n",
    "            \"legal firearm\", \"legal gun\", \"gun homicide\", \"gun advocate\", \"negligent discharge\", \n",
    "            \"accidental discharge\", \"firearm violence\", \"firearm-related violence\"]    \n",
    "    \n",
    "    strings = row['quotation']\n",
    "    key_word = [key for key in keywords if key.upper() in strings.upper()]\n",
    "    return ', '.join(key_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "537f1874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processes one chunk of data: filters rows to keep only those containing at least one keyword, and saves the chunk\n",
    "# to hard drive. \n",
    "def process_chunk(year, chunk, idx):\n",
    "    print(f'Processing chunk number: {idx} from year: {year}')\n",
    "    \n",
    "    # Select only columns of interest from data\n",
    "    selected_columns = chunk[[\"speaker\", \"qids\", \"date\", \"quotation\"]]\n",
    "    filtered_chunk = selected_columns.copy()\n",
    "    \n",
    "    # Apply filter to keep only columns containing at least a keyword from the list defined above\n",
    "    filtered_chunk['keyword'] = filtered_chunk.apply(keyword, axis=1)\n",
    "    filtered_chunk = filtered_chunk[filtered_chunk.keyword != '']\n",
    "    \n",
    "    # Save the chunk to hard drive to free up active memory\n",
    "    filtered_chunk.to_pickle(\"/Users/Justin/Desktop/ADA_project/processed_dfs/\" + str(year) + \"/\" + str(idx) + \n",
    "                             \"chunk_with_keyword.pkl\", compression='infer', protocol=4)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7b09a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk number: 1 from year: 2015\n",
      "Processing chunk number: 2 from year: 2015\n",
      "Processing chunk number: 3 from year: 2015\n",
      "Processing chunk number: 4 from year: 2015\n",
      "Processing chunk number: 5 from year: 2015\n",
      "Processing chunk number: 6 from year: 2015\n",
      "Processing chunk number: 7 from year: 2015\n",
      "Processing chunk number: 8 from year: 2015\n",
      "Processing chunk number: 9 from year: 2015\n",
      "Processing chunk number: 10 from year: 2015\n",
      "Processing chunk number: 11 from year: 2015\n",
      "Processing chunk number: 12 from year: 2015\n",
      "Processing chunk number: 13 from year: 2015\n",
      "Processing chunk number: 14 from year: 2015\n",
      "Processing chunk number: 1 from year: 2016\n",
      "Processing chunk number: 2 from year: 2016\n",
      "Processing chunk number: 3 from year: 2016\n",
      "Processing chunk number: 4 from year: 2016\n",
      "Processing chunk number: 5 from year: 2016\n",
      "Processing chunk number: 6 from year: 2016\n",
      "Processing chunk number: 7 from year: 2016\n",
      "Processing chunk number: 8 from year: 2016\n",
      "Processing chunk number: 9 from year: 2016\n",
      "Processing chunk number: 10 from year: 2016\n",
      "Processing chunk number: 1 from year: 2017\n",
      "Processing chunk number: 2 from year: 2017\n",
      "Processing chunk number: 3 from year: 2017\n",
      "Processing chunk number: 4 from year: 2017\n",
      "Processing chunk number: 5 from year: 2017\n",
      "Processing chunk number: 6 from year: 2017\n",
      "Processing chunk number: 7 from year: 2017\n",
      "Processing chunk number: 8 from year: 2017\n",
      "Processing chunk number: 9 from year: 2017\n",
      "Processing chunk number: 10 from year: 2017\n",
      "Processing chunk number: 11 from year: 2017\n",
      "Processing chunk number: 12 from year: 2017\n",
      "Processing chunk number: 13 from year: 2017\n",
      "Processing chunk number: 14 from year: 2017\n",
      "Processing chunk number: 15 from year: 2017\n",
      "Processing chunk number: 16 from year: 2017\n",
      "Processing chunk number: 17 from year: 2017\n",
      "Processing chunk number: 18 from year: 2017\n",
      "Processing chunk number: 1 from year: 2018\n",
      "Processing chunk number: 2 from year: 2018\n",
      "Processing chunk number: 3 from year: 2018\n",
      "Processing chunk number: 4 from year: 2018\n",
      "Processing chunk number: 5 from year: 2018\n",
      "Processing chunk number: 6 from year: 2018\n",
      "Processing chunk number: 7 from year: 2018\n",
      "Processing chunk number: 8 from year: 2018\n",
      "Processing chunk number: 9 from year: 2018\n",
      "Processing chunk number: 10 from year: 2018\n",
      "Processing chunk number: 11 from year: 2018\n",
      "Processing chunk number: 12 from year: 2018\n",
      "Processing chunk number: 13 from year: 2018\n",
      "Processing chunk number: 14 from year: 2018\n",
      "Processing chunk number: 15 from year: 2018\n",
      "Processing chunk number: 16 from year: 2018\n",
      "Processing chunk number: 17 from year: 2018\n",
      "Processing chunk number: 18 from year: 2018\n",
      "Processing chunk number: 19 from year: 2018\n",
      "Processing chunk number: 1 from year: 2019\n",
      "Processing chunk number: 2 from year: 2019\n",
      "Processing chunk number: 3 from year: 2019\n",
      "Processing chunk number: 4 from year: 2019\n",
      "Processing chunk number: 5 from year: 2019\n",
      "Processing chunk number: 6 from year: 2019\n",
      "Processing chunk number: 7 from year: 2019\n",
      "Processing chunk number: 8 from year: 2019\n",
      "Processing chunk number: 9 from year: 2019\n",
      "Processing chunk number: 10 from year: 2019\n",
      "Processing chunk number: 11 from year: 2019\n",
      "Processing chunk number: 12 from year: 2019\n",
      "Processing chunk number: 13 from year: 2019\n",
      "Processing chunk number: 14 from year: 2019\n",
      "Processing chunk number: 15 from year: 2019\n"
     ]
    }
   ],
   "source": [
    "# Iterate over all years of data instantly\n",
    "years = [2015, 2016, 2017, 2018, 2019]\n",
    "\n",
    "for year in years:\n",
    "    # Open the entire dataset for a year and split into chunks of size chunksize: \n",
    "    df_reader = pd.read_json('/Users/Justin/Desktop/ADA_project/Quote_Bank/quotes-' + str(year) + '.json.bz2',\n",
    "                         lines=True, compression='bz2', chunksize=1500000)\n",
    "    \n",
    "    # idx refers to chunk number: \n",
    "    idx = 0\n",
    "    \n",
    "    # Iterate over all chunks of a year of data:\n",
    "    for chunk in df_reader:\n",
    "        idx += 1\n",
    "        # Apply function to filter out data, and keep only quotes with keywords\n",
    "        # Function also saves each chunk to hard drive once done to speed up execution\n",
    "        process_chunk(year, chunk, idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d1cfdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which sequentially opens all pre-processed chunks and saves them to a single list\n",
    "def open_chunks(year, list_dfs):\n",
    "    common_path = '/Users/Justin/Desktop/ADA_project/processed_dfs/'\n",
    "    file_name = 'chunk_with_keyword.pkl'\n",
    "    \n",
    "    for file in listdir(common_path + str(year) + '/'):\n",
    "        \n",
    "        # Macs generate a hidden \".DS_Store\" file which contains MetaData about the folder content.\n",
    "        # The listdir() will identify this file, so we skip over this iterate of the for loop as the\n",
    "        # function will otherwise fail. \n",
    "        if file == '.DS_Store':\n",
    "            continue\n",
    "            \n",
    "        small_df = pd.read_pickle(common_path + str(year) + '/' + file, compression='infer')\n",
    "        list_dfs.append(small_df)\n",
    "    \n",
    "    return list_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44695b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all years of data instantly\n",
    "years = [2015, 2016, 2017, 2018, 2019]\n",
    "\n",
    "# The final dataframe to store the filtered Quote Bank data:\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "# execute the open_chunks function for all years of dataset and save the result to final_df: \n",
    "for year in years: \n",
    "    list_dfs = []\n",
    "    temp_df = pd.concat(open_chunks(year, list_dfs), ignore_index=True)\n",
    "    final_df = pd.concat([final_df, temp_df])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "927fee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling the final dataframe to share with other team members: \n",
    "final_df.to_pickle(\"/Users/Justin/Desktop/ADA_project/final_dataset/final_df.pkl\", compression='infer', protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70baa109",
   "metadata": {},
   "source": [
    "### Note for other team members: \n",
    "For other team members wanting to work with the final dataset, you should store the zipped/pickled final dataframe on your hard drive (in the correct repository), load the required libraries and execute the code from this cell onwards. \n",
    "The following cell will load the final pickled dataset into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75877849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>date</th>\n",
       "      <th>quotation</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dan Bongino</td>\n",
       "      <td>[Q16200445]</td>\n",
       "      <td>2015-04-14 15:37:28</td>\n",
       "      <td>I think you were almost setting yourself up fo...</td>\n",
       "      <td>gun crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2015-06-17 16:00:00</td>\n",
       "      <td>It is truly unfortunate that legislators spent...</td>\n",
       "      <td>firearm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mark Howell</td>\n",
       "      <td>[Q16229080, Q6768121]</td>\n",
       "      <td>2015-05-17 22:11:17</td>\n",
       "      <td>99.99% of the time where someone brings a fire...</td>\n",
       "      <td>firearm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2015-02-03 21:21:45</td>\n",
       "      <td>At this point we are investigating the possibi...</td>\n",
       "      <td>firearm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Peter Doocy</td>\n",
       "      <td>[Q7173707]</td>\n",
       "      <td>2015-12-04 02:14:07</td>\n",
       "      <td>So the president thinks that when there are tw...</td>\n",
       "      <td>gun law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Greg Abbott</td>\n",
       "      <td>[Q5605224, Q5605225]</td>\n",
       "      <td>2015-12-31 19:21:35</td>\n",
       "      <td>symbolic in retaining some liberty, similar to...</td>\n",
       "      <td>gun owner, gun ownership</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2015-09-11 07:42:30</td>\n",
       "      <td>conceal carr handguns, big handguns. it doesn'...</td>\n",
       "      <td>handguns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Michael Moore</td>\n",
       "      <td>[Q10430120, Q174908, Q1752903, Q1928646, Q2005...</td>\n",
       "      <td>2015-12-30 22:03:39</td>\n",
       "      <td>During the Vietnam War, you saw what was happe...</td>\n",
       "      <td>mass shooting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adam Winkler</td>\n",
       "      <td>[Q21288375, Q4679989]</td>\n",
       "      <td>2015-06-22 12:53:07</td>\n",
       "      <td>gun rights and gun control are not only compat...</td>\n",
       "      <td>gun control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Budi Waseso</td>\n",
       "      <td>[Q19753012]</td>\n",
       "      <td>2015-02-17 12:22:18</td>\n",
       "      <td>The possession of illegal guns is very dangero...</td>\n",
       "      <td>legal gun, legal gun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         speaker                                               qids  \\\n",
       "0    Dan Bongino                                        [Q16200445]   \n",
       "1           None                                                 []   \n",
       "2    Mark Howell                              [Q16229080, Q6768121]   \n",
       "3           None                                                 []   \n",
       "4    Peter Doocy                                         [Q7173707]   \n",
       "5    Greg Abbott                               [Q5605224, Q5605225]   \n",
       "6           None                                                 []   \n",
       "7  Michael Moore  [Q10430120, Q174908, Q1752903, Q1928646, Q2005...   \n",
       "8   Adam Winkler                              [Q21288375, Q4679989]   \n",
       "9    Budi Waseso                                        [Q19753012]   \n",
       "\n",
       "                 date                                          quotation  \\\n",
       "0 2015-04-14 15:37:28  I think you were almost setting yourself up fo...   \n",
       "1 2015-06-17 16:00:00  It is truly unfortunate that legislators spent...   \n",
       "2 2015-05-17 22:11:17  99.99% of the time where someone brings a fire...   \n",
       "3 2015-02-03 21:21:45  At this point we are investigating the possibi...   \n",
       "4 2015-12-04 02:14:07  So the president thinks that when there are tw...   \n",
       "5 2015-12-31 19:21:35  symbolic in retaining some liberty, similar to...   \n",
       "6 2015-09-11 07:42:30  conceal carr handguns, big handguns. it doesn'...   \n",
       "7 2015-12-30 22:03:39  During the Vietnam War, you saw what was happe...   \n",
       "8 2015-06-22 12:53:07  gun rights and gun control are not only compat...   \n",
       "9 2015-02-17 12:22:18  The possession of illegal guns is very dangero...   \n",
       "\n",
       "                    keyword  \n",
       "0                 gun crime  \n",
       "1                   firearm  \n",
       "2                   firearm  \n",
       "3                   firearm  \n",
       "4                   gun law  \n",
       "5  gun owner, gun ownership  \n",
       "6                  handguns  \n",
       "7             mass shooting  \n",
       "8               gun control  \n",
       "9      legal gun, legal gun  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure to modify the path in the function below so that it is compatible with your computer\n",
    "final_df = pd.read_pickle(\"/Users/Justin/Desktop/ADA_project/final_dataset/final_df.pkl\", compression='infer')\n",
    "final_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef004fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
